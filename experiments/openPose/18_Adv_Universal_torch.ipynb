{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal noise\n",
    "\n",
    "This notebook computes a universal noise pattern, which can be added to any image \n",
    "and missleads the open pose network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/ax/miniconda3/envs/masterThesisPytorchOpenpose/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "/home/ax/.local/lib/python3.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.8) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# imports\n",
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import copy\n",
    "\n",
    "\n",
    "from torch_openpose.body import Body\n",
    "from torch_openpose import util\n",
    "\n",
    "from PIL import Image\n",
    "import glob \n",
    "import wandb\n",
    "import random\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "\n",
    "\n",
    "logging.getLogger(\"wandb\").setLevel(logging.ERROR)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_imgfile(path, width=None, height=None, image_type=cv2.IMREAD_COLOR):\n",
    "    val_image = cv2.imread(path, image_type)\n",
    "    if width is not None and height is not None:\n",
    "        val_image = cv2.resize(val_image, (width, height))\n",
    "    return val_image\n",
    "\n",
    "\n",
    "def load_batch(training_paths, start_index, batch_size, width=432, height=368):\n",
    "    i = start_index\n",
    "    batch = []\n",
    "    while len(batch) < batch_size:\n",
    "        if i >= len(training_paths):\n",
    "            i = 0\n",
    "        batch.append(read_imgfile(str(training_paths[i]), width, height))\n",
    "        i += 1\n",
    "    return np.asarray(batch), i\n",
    "\n",
    "def batch_to_input_tensor(batch, stride=8, padValue=128):\n",
    "    tensor_list = []\n",
    "    transform_func = transforms.ToTensor()\n",
    "    for image in batch:\n",
    "        imageToTest_padded, _ = util.padRightDownCorner(image, stride, padValue)\n",
    "        tensor_list.append(\n",
    "            transform_func(np.ascontiguousarray(imageToTest_padded))\n",
    "        )\n",
    "\n",
    "    return torch.stack(tensor_list)\n",
    "def loss_function(batch_tensor, target_heat_tensor, target_paf_tensor):\n",
    "    loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "    \n",
    "    batch_size = batch_tensor.shape[0]\n",
    "    target_heat_tensor_batch = target_heat_tensor.repeat(batch_size, 1, 1, 1)\n",
    "    target_paf_tensor_batch = target_paf_tensor.repeat(batch_size, 1, 1, 1)\n",
    "    \n",
    "    test_batch = Variable(batch_tensor, requires_grad=True)\n",
    "    \n",
    "    # compute heatmaps\n",
    "    paf_tensor, heat_tensor = body_estimation.model(test_batch)\n",
    "\n",
    "    # compute loss for heat and paf\n",
    "    loss_heat = loss_fn(heat_tensor, target_heat_tensor_batch)\n",
    "    loss_paf = loss_fn(paf_tensor, target_paf_tensor_batch)\n",
    "\n",
    "    loss_total = loss_heat + loss_paf\n",
    "\n",
    "    # get the total loss as a number\n",
    "    total_loss_value = loss_total.item()\n",
    "\n",
    "    # Zero the gradients before running the backward pass.\n",
    "    body_estimation.model.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
    "    # parameters of the model. Internally, the parameters of each Module are stored\n",
    "    # in Tensors with requires_grad=True, so this call will compute gradients for\n",
    "    # all learnable parameters in the model.\n",
    "    loss_total.backward(retain_graph=True)\n",
    "    \n",
    "    gradient = torch.mean(test_batch.grad, dim=0)\n",
    "    return gradient, total_loss_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/alexus/18_adv_universal_torch\" target=\"_blank\">https://app.wandb.ai/alexus/18_adv_universal_torch</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/alexus/18_adv_universal_torch/runs/2ezlwxsu\" target=\"_blank\">https://app.wandb.ai/alexus/18_adv_universal_torch/runs/2ezlwxsu</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run config\n",
    "IMAGE_WIDTH, IMAGE_HEIGHT = 432, 368\n",
    "OUTPUT_WIDTH, OUTPUT_HEIGHT = 54, 46\n",
    "image_path_target = '../data/images/dri_target_far_2.jpg'\n",
    "image_path_source = '../data/images/dri_source_2.jpg'\n",
    "train_dir = '../data/cocoval2017Humans/train'\n",
    "test_dir = '../data/cocoval2017Humans/test'\n",
    "image_target = read_imgfile(image_path_target, width=IMAGE_WIDTH, height=IMAGE_HEIGHT)\n",
    "image_source = read_imgfile(image_path_source, width=IMAGE_WIDTH, height=IMAGE_HEIGHT)\n",
    "\n",
    "\n",
    "run = wandb.init(\n",
    "    project = \"18_adv_universal_torch\", \n",
    "    name = 'make it work',\n",
    "    config={\n",
    "        \"epochs\": 1,\n",
    "        \"epsilon\": 5000,\n",
    "        \"batch_size\": 16,\n",
    "        \"image_width\": IMAGE_WIDTH,\n",
    "        \"image_height\": IMAGE_HEIGHT,\n",
    "    }\n",
    ")\n",
    "\n",
    "training_paths = pathlib.Path(train_dir).glob('*.jpg')\n",
    "training_paths = sorted([x for x in training_paths])\n",
    "test_paths = pathlib.Path(test_dir).glob('*.jpg')\n",
    "test_paths = sorted([x for x in test_paths])\n",
    "body_estimation = Body('/home/ax/Programs/pytorch-openpose/model/body_pose_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_heat_np.shape= (46, 54, 19)\n",
      "target_paf_np.shape= (46, 54, 38)\n"
     ]
    }
   ],
   "source": [
    "# get the target heat and paf\n",
    "input_tensor = body_estimation.image_to_input_tensor(image_target)\n",
    "target_heat_np, target_heat_tensor = body_estimation.compute_heatmap(input_tensor)\n",
    "target_paf_np, target_paf_tensor = body_estimation.compute_paf(input_tensor)\n",
    "print(f\"target_heat_np.shape= {target_heat_np.shape}\")\n",
    "print(f\"target_paf_np.shape= {target_paf_np.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.shape = (4, 368, 432, 3)\n",
      "batch_tensor.shape = torch.Size([4, 3, 368, 432])  torch.FloatTensor\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d7312768560e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"batch_tensor.shape = {batch_tensor.shape}  {batch_tensor.type()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_heat_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_paf_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-c7c089b48d59>\u001b[0m in \u001b[0;36mloss_function\u001b[0;34m(batch_tensor, target_heat_tensor, target_paf_tensor)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# in Tensors with requires_grad=True, so this call will compute gradients for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# all learnable parameters in the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mloss_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/masterThesisPytorchOpenpose/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/masterThesisPytorchOpenpose/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch, _ = load_batch(training_paths, 0, 4)\n",
    "print(f\"batch.shape = {batch.shape}\")\n",
    "batch_tensor = batch_to_input_tensor(batch)\n",
    "print(f\"batch_tensor.shape = {batch_tensor.shape}  {batch_tensor.type()}\")\n",
    "\n",
    "grad, loss = loss_function(batch_tensor, target_heat_tensor, target_paf_tensor)\n",
    "print(loss)\n",
    "print(grad.shape)\n",
    "print(body_estimation.image_to_input_tensor(image_source).shape)\n",
    "print(loss)\n",
    "print(grad.shape)\n",
    "\n",
    "plt.imshow(grad_image / 256.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n",
      "250 per epoch\n"
     ]
    }
   ],
   "source": [
    "if not \"training_stats\" in vars():\n",
    "    print(\"init\")\n",
    "    # where does the current batch start\n",
    "    training_stats = {\n",
    "        'gobal_step': 0,\n",
    "        'batch_index': 0,\n",
    "        'universal_noise': np.zeros((3, IMAGE_HEIGHT, IMAGE_WIDTH), dtype=np.float32),\n",
    "        'file_name': 'universal_noise_torch'\n",
    "    }\n",
    "    \n",
    "steps = len(training_paths) // run.config.batch_size\n",
    "print(f\"{steps} per epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/250 [04:25<5:56:54, 86.70s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-550cabe56728>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mbatch_tensor_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_tensor\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeated_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_tensor_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_heat_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_paf_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gobal_step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c7c089b48d59>\u001b[0m in \u001b[0;36mloss_function\u001b[0;34m(batch_tensor, target_heat_tensor, target_paf_tensor)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# in Tensors with requires_grad=True, so this call will compute gradients for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# all learnable parameters in the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mloss_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/masterThesisPytorchOpenpose/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/masterThesisPytorchOpenpose/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### ================= TRAINING ================= ###\n",
    "for epoch in range(run.config.epochs):\n",
    "    print(f\"run {epoch + 1}/{run.config.epochs}\")\n",
    "    for step in tqdm(range(steps)):        \n",
    "        batch, training_stats['batch_index'] = load_batch(training_paths, training_stats['batch_index'], wandb.config.batch_size)\n",
    "\n",
    "        repeated_noise = np.repeat(np.expand_dims(training_stats['universal_noise'], axis=0), wandb.config.batch_size, 0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        batch_tensor = batch_to_input_tensor(batch)\n",
    "        batch_tensor_noise = batch_tensor + torch.tensor(repeated_noise)\n",
    "\n",
    "        gradient, loss_val = loss_function(batch_tensor_noise, target_heat_tensor, target_paf_tensor)\n",
    "\n",
    "        wandb.log({'loss': loss_val}, step=training_stats['gobal_step'])\n",
    "        \n",
    "\n",
    "        ### ================= UPDATE STEP ================= ###\n",
    "        scaled_gradient = (run.config.epsilon * gradient.numpy())            \n",
    "\n",
    "        training_stats['universal_noise'] = training_stats['universal_noise'] - scaled_gradient\n",
    "        training_stats['universal_noise'] = np.clip(training_stats['universal_noise'], 0, 255)\n",
    "        training_stats['gobal_step'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:masterThesisPytorchOpenpose] *",
   "language": "python",
   "name": "conda-env-masterThesisPytorchOpenpose-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
